{"cells":[{"cell_type":"markdown","metadata":{"id":"Yat7_CVZnwx_"},"source":["# Mount Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16377,"status":"ok","timestamp":1749103400024,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"uAutu3P7nq-P","outputId":"74d0f8ca-e78c-4c4c-97b4-c88036f31782"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n","FOLDERNAME = \"cs231n-project\"\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"]},{"cell_type":"markdown","metadata":{"id":"iHnn4_5ynzhQ"},"source":["# GPU if available"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4627,"status":"ok","timestamp":1749103404653,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"imBDBfJSnyfb","outputId":"521af893-e752-47dd-e028-6e911e8315f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{"id":"IuZjdiQgn4Tn"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1749103404672,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"nEFJ3ck0n2tO"},"outputs":[],"source":["dataset_path = f\"/content/drive/My Drive/cs231n-project/dataset/Taskent\"\n","\n","dataset_size = 21\n","# test_indices = [1,2]\n","# train_indices = [i for i in range(dataset_size) if not i in test_indices]\n","# train_indices = [0,3,4]"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1749103404897,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"IxAWpSqFn5OZ"},"outputs":[],"source":["from image_dataset import *"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18825,"status":"ok","timestamp":1749103423723,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"VnQvRNlnn6Os","outputId":"66a4f774-72aa-4620-fe3c-f96ad4d5031c"},"outputs":[{"name":"stdout","output_type":"stream","text":["__init__ PetroSubImageDataset: /content/drive/My Drive/cs231n-project/dataset/Taskent\n","         , image_indices=None\n","         , sub_image_size=480\n","__init__ BaseSubImageDataset with: /content/drive/My Drive/cs231n-project/dataset/Taskent/img\n","         , image_indices=None\n","         , sub_image_size=480\n","         , mask=False\n","__init__ BaseSubImageDataset with: /content/drive/My Drive/cs231n-project/dataset/Taskent/masks_machine\n","         , image_indices=None\n","         , sub_image_size=480\n","         , mask=True\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/My Drive/cs231n-project/image_dataset.py:211: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n","  images = torch.stack([torch.from_numpy(img) for img in images])\n"]}],"source":["dataset = PetroTrainTestSplitDataset(folder_path=dataset_path)\n","\n","train_dataset = dataset['train']\n","test_dataset = dataset['test']"]},{"cell_type":"markdown","metadata":{"id":"WDfbKAHqn87l"},"source":["# Load DINO Model and helper functions"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":479,"status":"ok","timestamp":1749103424206,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"Xr83YLOSn7LJ"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from clip_dino import DINOSegmentation, compute_iou\n","from dino_model import DINOPatchClassifier\n","from tqdm import tqdm\n","from einops import rearrange\n","import numpy as np"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8382,"status":"ok","timestamp":1749103432590,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"LDtROiJcn-fg","outputId":"1a8ea0d0-6488-4e3f-dfe1-f3f288561888"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n","Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall8_pretrain.pth\n","100%|██████████| 82.7M/82.7M [00:00\u003c00:00, 153MB/s]\n"]},{"data":{"text/plain":["VisionTransformer(\n","  (patch_embed): PatchEmbed(\n","    (proj): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))\n","  )\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (blocks): ModuleList(\n","    (0-11): 12 x Block(\n","      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=384, out_features=384, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): Identity()\n","      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate='none')\n","        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","  (head): Identity()\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Load smallest dino model. ViT-S/8. Here ViT-S has ~22M parameters and\n","# works on 8x8 patches.\n","dino_model = torch.hub.load('facebookresearch/dino:main', 'dino_vits8')\n","dino_model.eval().to(device)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1749103432595,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"vDrKQULkoAFQ"},"outputs":[],"source":["from torchvision import transforms as T\n","\n","transform = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","\n","# transform = T.Compose([\n","#     # T.Resize((480, 480)),\n","#     T.ToTensor(),\n","#     T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","# ])\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1749103432600,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"YuUJI2tUoBsY"},"outputs":[],"source":["def get_dino_tokens_batch(X_batch):\n","\n","    # X_batch.shape = [batch_size,480,480,3]\n","\n","    X_batch = X_batch.float() / 255.0 # normalize\n","    # X_batch = X_batch.permute(0,3,1,2) # [N,H,W,C] -\u003e [N,C,H,W]\n","    X_transform = torch.stack([\n","        transform(x) for x in X_batch\n","    ])\n","    X_transform = X_transform.to(device)\n","\n","    w, h = X_transform.shape[2:]\n","    # 480,480\n","\n","    with torch.no_grad():\n","        attn = dino_model.get_last_selfattention(X_transform)[:, :, 0, 1:]\n","        # (N,6,3600)\n","        # print(f\"attn.shape={attn.shape}\")\n","        nh, tokens = attn.shape[1:]\n","        w_feat, h_feat = w // 8, h // 8\n","        attn = attn.reshape(-1, nh, w_feat, h_feat)\n","        attn = torch.nn.functional.interpolate(attn, scale_factor=8, mode=\"nearest\").cpu().numpy()\n","        all_tokens = dino_model.get_intermediate_layers(X_transform, n=1)[0]  # (N, 1+pixels, D)\n","    return all_tokens.cpu()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1749103432638,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"3W_J2HuHoC1f"},"outputs":[],"source":["# def get_patchwise_biotic_ornot(Y_batch):\n","#     \"\"\"\n","#     Input:\n","#         Y_batch: (N, 480, 480) segmentation labels as a NumPy array or torch.Tensor\n","\n","#     Output:\n","#         (N, 60, 60) torch.Tensor where each value is 1 (biotic) or 0 (non-biotic)\n","#     \"\"\"\n","\n","#     if isinstance(Y_batch, torch.Tensor):\n","#         Y_batch = Y_batch.cpu().numpy()\n","\n","#     # Define class sets\n","#     abiotic = {1, 2, 11, 17}\n","#     biotic = {3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16}\n","#     scale_bar = {8}\n","\n","#     biotic_ornot_mask = np.full_like(Y_batch, fill_value=3, dtype=np.uint8)\n","#     biotic_ornot_mask[np.isin(Y_batch, list(abiotic))] = 0\n","#     biotic_ornot_mask[np.isin(Y_batch, list(biotic))] = 1\n","#     biotic_ornot_mask[np.isin(Y_batch, list(scale_bar))] = 0\n","\n","#     # Rearrange to 8x8 patches\n","#     patches = rearrange(biotic_ornot_mask, 'n (h ph) (w pw) -\u003e n h w ph pw', ph=8, pw=8)\n","#     # patches shape = (N, 60, 60, 8, 8)\n","\n","#     # Check if any pixel in each 8x8 patch is biotic (== 1)\n","#     patchwise_biotic = (patches == 1).any(axis=(-1, -2)).astype(np.uint8)\n","#     # shape = (N, 60, 60)\n","\n","#     return torch.tensor(patchwise_biotic)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":454,"status":"ok","timestamp":1749103433093,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"du5Mrq5YpFAP"},"outputs":[],"source":["import numpy as np\n","import torch\n","from einops import rearrange\n","from scipy.stats import mode\n","\n","def get_patchwise_mode(Y_batch):\n","\n","    if isinstance(Y_batch, torch.Tensor):\n","        Y_batch = Y_batch.cpu().numpy()\n","\n","    # Rearrange to 8x8 patches\n","    patches = rearrange(Y_batch, 'n (h ph) (w pw) -\u003e n h w (ph pw)', ph=8, pw=8)\n","    # shape: (N, H//8, W//8, 64)\n","\n","    # Compute mode along last axis\n","    patch_modes = mode(patches, axis=-1).mode  # shape: (N, H//8, W//8)\n","\n","    return torch.tensor(patch_modes, dtype=torch.uint8)"]},{"cell_type":"markdown","metadata":{"id":"Hx3B0N8hoSsK"},"source":["## WandB"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"elapsed":73108,"status":"ok","timestamp":1749103506199,"user":{"displayName":"Rohit Makhija","userId":"11045331401392625627"},"user_tz":420},"id":"CII-KGacoT2F","outputId":"ae0d559e-74e4-4f78-dee7-dd917f0850d8"},"outputs":[{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) =\u003e {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() =\u003e {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() =\u003e reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data =\u003e {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W\u0026B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthisisrmak\u001b[0m (\u001b[33mthisisrmak-stanford\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"KpJSgQMgoGXk"},"source":["# Run test/train loop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"XAkAfFaGoEkQ"},"outputs":[{"data":{"text/html":["Finishing previous runs because reinit is set to 'default'."],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run \u003cstrong style=\"color:#cdcd00\"\u003erun-patchwise-mode\u003c/strong\u003e at: \u003ca href='https://wandb.ai/thisisrmak-stanford/dinov2-biotic-08/runs/ojmxlsih' target=\"_blank\"\u003ehttps://wandb.ai/thisisrmak-stanford/dinov2-biotic-08/runs/ojmxlsih\u003c/a\u003e\u003cbr\u003e View project at: \u003ca href='https://wandb.ai/thisisrmak-stanford/dinov2-biotic-08' target=\"_blank\"\u003ehttps://wandb.ai/thisisrmak-stanford/dinov2-biotic-08\u003c/a\u003e\u003cbr\u003eSynced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e./wandb/run-20250605_061743-ojmxlsih/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.19.11"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/wandb/run-20250605_061754-w4ldx9w1\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href='https://wandb.ai/thisisrmak-stanford/dinov2-biotic-nb-08/runs/w4ldx9w1' target=\"_blank\"\u003erun-patchwise-mode\u003c/a\u003e\u003c/strong\u003e to \u003ca href='https://wandb.ai/thisisrmak-stanford/dinov2-biotic-nb-08' target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href='https://wandb.me/developer-guide' target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at \u003ca href='https://wandb.ai/thisisrmak-stanford/dinov2-biotic-nb-08' target=\"_blank\"\u003ehttps://wandb.ai/thisisrmak-stanford/dinov2-biotic-nb-08\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at \u003ca href='https://wandb.ai/thisisrmak-stanford/dinov2-biotic-nb-08/runs/w4ldx9w1' target=\"_blank\"\u003ehttps://wandb.ai/thisisrmak-stanford/dinov2-biotic-nb-08/runs/w4ldx9w1\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Train Epoch 1/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.34s/it, iou=0.04, loss=1.60]\n","Val Epoch 1/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.27s/it, iou=0.04, loss=2.06]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: Train Loss=2.3537, Acc=0.4699, IoU=0.0320 | Val Loss=1.9126, Acc=0.4644, IoU=0.0333\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 2/50: 100%|██████████| 24/24 [03:21\u003c00:00,  8.40s/it, iou=0.05, loss=0.76]\n","Val Epoch 2/50: 100%|██████████| 8/8 [01:07\u003c00:00,  8.44s/it, iou=0.05, loss=1.26]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 2: Train Loss=1.5335, Acc=0.4908, IoU=0.0332 | Val Loss=1.1716, Acc=0.5990, IoU=0.0457\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 3/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.35s/it, iou=0.07, loss=0.90]\n","Val Epoch 3/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.33s/it, iou=0.09, loss=1.02]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 3: Train Loss=1.2662, Acc=0.5372, IoU=0.0437 | Val Loss=0.9746, Acc=0.6522, IoU=0.0626\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 4/50: 100%|██████████| 24/24 [03:23\u003c00:00,  8.49s/it, iou=0.09, loss=0.86]\n","Val Epoch 4/50: 100%|██████████| 8/8 [01:08\u003c00:00,  8.51s/it, iou=0.12, loss=0.98]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 4: Train Loss=1.0951, Acc=0.5738, IoU=0.0507 | Val Loss=0.9874, Acc=0.6521, IoU=0.0698\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 5/50: 100%|██████████| 24/24 [03:22\u003c00:00,  8.44s/it, iou=0.10, loss=0.73]\n","Val Epoch 5/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.37s/it, iou=0.13, loss=0.93]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 5: Train Loss=1.0241, Acc=0.5975, IoU=0.0530 | Val Loss=0.9535, Acc=0.6644, IoU=0.0728\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 6/50: 100%|██████████| 24/24 [03:21\u003c00:00,  8.39s/it, iou=0.11, loss=0.63]\n","Val Epoch 6/50: 100%|██████████| 8/8 [01:07\u003c00:00,  8.41s/it, iou=0.13, loss=0.90]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 6: Train Loss=0.9599, Acc=0.6203, IoU=0.0566 | Val Loss=0.9137, Acc=0.6783, IoU=0.0741\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 7/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.36s/it, iou=0.11, loss=0.55]\n","Val Epoch 7/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.37s/it, iou=0.13, loss=0.87]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 7: Train Loss=0.9162, Acc=0.6337, IoU=0.0597 | Val Loss=0.8873, Acc=0.6870, IoU=0.0748\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 8/50: 100%|██████████| 24/24 [03:22\u003c00:00,  8.42s/it, iou=0.12, loss=0.51]\n","Val Epoch 8/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.30s/it, iou=0.13, loss=0.85]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 8: Train Loss=0.8866, Acc=0.6425, IoU=0.0619 | Val Loss=0.8655, Acc=0.6940, IoU=0.0769\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 9/50: 100%|██████████| 24/24 [03:21\u003c00:00,  8.41s/it, iou=0.12, loss=0.49]\n","Val Epoch 9/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.27s/it, iou=0.14, loss=0.83]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 9: Train Loss=0.8644, Acc=0.6509, IoU=0.0643 | Val Loss=0.8554, Acc=0.6979, IoU=0.0787\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 10/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.36s/it, iou=0.12, loss=0.48]\n","Val Epoch 10/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.29s/it, iou=0.14, loss=0.82]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 10: Train Loss=0.8462, Acc=0.6585, IoU=0.0659 | Val Loss=0.8507, Acc=0.6994, IoU=0.0805\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 11/50: 100%|██████████| 24/24 [03:18\u003c00:00,  8.27s/it, iou=0.13, loss=0.46]\n","Val Epoch 11/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.29s/it, iou=0.14, loss=0.81]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 11: Train Loss=0.8273, Acc=0.6661, IoU=0.0678 | Val Loss=0.8479, Acc=0.7012, IoU=0.0815\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 12/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.37s/it, iou=0.13, loss=0.43]\n","Val Epoch 12/50: 100%|██████████| 8/8 [01:07\u003c00:00,  8.40s/it, iou=0.15, loss=0.79]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 12: Train Loss=0.8047, Acc=0.6752, IoU=0.0696 | Val Loss=0.8377, Acc=0.7045, IoU=0.0829\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 13/50: 100%|██████████| 24/24 [03:22\u003c00:00,  8.43s/it, iou=0.13, loss=0.41]\n","Val Epoch 13/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.30s/it, iou=0.15, loss=0.78]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 13: Train Loss=0.7832, Acc=0.6831, IoU=0.0720 | Val Loss=0.8286, Acc=0.7082, IoU=0.0835\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 14/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.37s/it, iou=0.13, loss=0.38]\n","Val Epoch 14/50: 100%|██████████| 8/8 [01:07\u003c00:00,  8.45s/it, iou=0.15, loss=0.77]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 14: Train Loss=0.7642, Acc=0.6910, IoU=0.0750 | Val Loss=0.8124, Acc=0.7139, IoU=0.0847\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 15/50: 100%|██████████| 24/24 [03:21\u003c00:00,  8.39s/it, iou=0.13, loss=0.37]\n","Val Epoch 15/50: 100%|██████████| 8/8 [01:07\u003c00:00,  8.39s/it, iou=0.15, loss=0.77]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 15: Train Loss=0.7455, Acc=0.6970, IoU=0.0781 | Val Loss=0.8053, Acc=0.7153, IoU=0.0864\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 16/50: 100%|██████████| 24/24 [03:21\u003c00:00,  8.39s/it, iou=0.13, loss=0.37]\n","Val Epoch 16/50: 100%|██████████| 8/8 [01:07\u003c00:00,  8.40s/it, iou=0.15, loss=0.76]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 16: Train Loss=0.7360, Acc=0.7014, IoU=0.0795 | Val Loss=0.7977, Acc=0.7206, IoU=0.0868\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 17/50: 100%|██████████| 24/24 [03:19\u003c00:00,  8.33s/it, iou=0.12, loss=0.36]\n","Val Epoch 17/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.35s/it, iou=0.15, loss=0.77]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 17: Train Loss=0.7181, Acc=0.7090, IoU=0.0812 | Val Loss=0.7918, Acc=0.7221, IoU=0.0887\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 18/50: 100%|██████████| 24/24 [03:19\u003c00:00,  8.31s/it, iou=0.13, loss=0.34]\n","Val Epoch 18/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.29s/it, iou=0.16, loss=0.73]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 18: Train Loss=0.7092, Acc=0.7130, IoU=0.0831 | Val Loss=0.7794, Acc=0.7284, IoU=0.0893\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 19/50: 100%|██████████| 24/24 [03:19\u003c00:00,  8.30s/it, iou=0.13, loss=0.33]\n","Val Epoch 19/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.27s/it, iou=0.15, loss=0.75]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 19: Train Loss=0.6913, Acc=0.7220, IoU=0.0851 | Val Loss=0.7725, Acc=0.7297, IoU=0.0910\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 20/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.37s/it, iou=0.13, loss=0.32]\n","Val Epoch 20/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.37s/it, iou=0.16, loss=0.72]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 20: Train Loss=0.6832, Acc=0.7256, IoU=0.0867 | Val Loss=0.7673, Acc=0.7330, IoU=0.0933\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 21/50: 100%|██████████| 24/24 [03:19\u003c00:00,  8.31s/it, iou=0.13, loss=0.34]\n","Val Epoch 21/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.26s/it, iou=0.15, loss=0.77]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 21: Train Loss=0.6728, Acc=0.7313, IoU=0.0878 | Val Loss=0.7843, Acc=0.7263, IoU=0.0932\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 22/50: 100%|██████████| 24/24 [03:22\u003c00:00,  8.42s/it, iou=0.13, loss=0.35]\n","Val Epoch 22/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.31s/it, iou=0.16, loss=0.75]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 22: Train Loss=0.6740, Acc=0.7309, IoU=0.0884 | Val Loss=0.7982, Acc=0.7228, IoU=0.0940\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 23/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.37s/it, iou=0.13, loss=0.33]\n","Val Epoch 23/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.27s/it, iou=0.15, loss=0.78]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 23: Train Loss=0.6640, Acc=0.7353, IoU=0.0893 | Val Loss=0.8027, Acc=0.7213, IoU=0.0923\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 24/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.36s/it, iou=0.13, loss=0.31]\n","Val Epoch 24/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.30s/it, iou=0.17, loss=0.71]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 24: Train Loss=0.6508, Acc=0.7402, IoU=0.0909 | Val Loss=0.7794, Acc=0.7302, IoU=0.0964\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 25/50: 100%|██████████| 24/24 [03:21\u003c00:00,  8.39s/it, iou=0.13, loss=0.29]\n","Val Epoch 25/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.34s/it, iou=0.16, loss=0.74]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 25: Train Loss=0.6326, Acc=0.7486, IoU=0.0923 | Val Loss=0.7699, Acc=0.7342, IoU=0.0945\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 26/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.37s/it, iou=0.13, loss=0.29]\n","Val Epoch 26/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.32s/it, iou=0.16, loss=0.72]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 26: Train Loss=0.6195, Acc=0.7529, IoU=0.0939 | Val Loss=0.7601, Acc=0.7391, IoU=0.0937\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 27/50: 100%|██████████| 24/24 [03:19\u003c00:00,  8.32s/it, iou=0.12, loss=0.31]\n","Val Epoch 27/50: 100%|██████████| 8/8 [01:07\u003c00:00,  8.39s/it, iou=0.15, loss=0.77]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 27: Train Loss=0.6120, Acc=0.7574, IoU=0.0942 | Val Loss=0.7720, Acc=0.7376, IoU=0.0906\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 28/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.37s/it, iou=0.12, loss=0.31]\n","Val Epoch 28/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.28s/it, iou=0.15, loss=0.78]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 28: Train Loss=0.6164, Acc=0.7546, IoU=0.0929 | Val Loss=0.7814, Acc=0.7430, IoU=0.0887\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 29/50: 100%|██████████| 24/24 [03:22\u003c00:00,  8.42s/it, iou=0.13, loss=0.25]\n","Val Epoch 29/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.35s/it, iou=0.15, loss=0.76]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 29: Train Loss=0.6063, Acc=0.7622, IoU=0.0946 | Val Loss=0.7680, Acc=0.7484, IoU=0.0893\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 30/50: 100%|██████████| 24/24 [03:19\u003c00:00,  8.29s/it, iou=0.14, loss=0.22]\n","Val Epoch 30/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.36s/it, iou=0.16, loss=0.69]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 30: Train Loss=0.5951, Acc=0.7676, IoU=0.0958 | Val Loss=0.7277, Acc=0.7564, IoU=0.0938\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 31/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.35s/it, iou=0.13, loss=0.23]\n","Val Epoch 31/50: 100%|██████████| 8/8 [01:06\u003c00:00,  8.36s/it, iou=0.16, loss=0.74]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 31: Train Loss=0.5726, Acc=0.7773, IoU=0.0984 | Val Loss=0.7308, Acc=0.7547, IoU=0.0940\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 32/50: 100%|██████████| 24/24 [03:20\u003c00:00,  8.34s/it, iou=0.13, loss=0.25]\n","Val Epoch 32/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.04s/it, iou=0.16, loss=0.73]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 32: Train Loss=0.5749, Acc=0.7751, IoU=0.0993 | Val Loss=0.7578, Acc=0.7491, IoU=0.0927\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 33/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.00s/it, iou=0.14, loss=0.27]\n","Val Epoch 33/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.99s/it, iou=0.16, loss=0.76]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 33: Train Loss=0.5820, Acc=0.7757, IoU=0.0982 | Val Loss=0.7732, Acc=0.7355, IoU=0.0954\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 34/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.01s/it, iou=0.14, loss=0.29]\n","Val Epoch 34/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.98s/it, iou=0.17, loss=0.71]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 34: Train Loss=0.5962, Acc=0.7667, IoU=0.0982 | Val Loss=0.7897, Acc=0.7300, IoU=0.0974\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 35/50: 100%|██████████| 24/24 [03:13\u003c00:00,  8.05s/it, iou=0.14, loss=0.28]\n","Val Epoch 35/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.02s/it, iou=0.16, loss=0.76]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 35: Train Loss=0.5890, Acc=0.7731, IoU=0.0989 | Val Loss=0.7804, Acc=0.7326, IoU=0.0957\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 36/50: 100%|██████████| 24/24 [03:11\u003c00:00,  7.98s/it, iou=0.14, loss=0.27]\n","Val Epoch 36/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.07s/it, iou=0.16, loss=0.73]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 36: Train Loss=0.5760, Acc=0.7750, IoU=0.1012 | Val Loss=0.7715, Acc=0.7320, IoU=0.0938\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 37/50: 100%|██████████| 24/24 [03:11\u003c00:00,  7.99s/it, iou=0.14, loss=0.24]\n","Val Epoch 37/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.01s/it, iou=0.16, loss=0.75]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 37: Train Loss=0.5532, Acc=0.7875, IoU=0.1035 | Val Loss=0.7595, Acc=0.7440, IoU=0.0935\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 38/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.02s/it, iou=0.14, loss=0.21]\n","Val Epoch 38/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.99s/it, iou=0.17, loss=0.72]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 38: Train Loss=0.5348, Acc=0.7936, IoU=0.1049 | Val Loss=0.7437, Acc=0.7526, IoU=0.0951\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 39/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.01s/it, iou=0.14, loss=0.20]\n","Val Epoch 39/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.04s/it, iou=0.16, loss=0.73]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 39: Train Loss=0.5139, Acc=0.8045, IoU=0.1066 | Val Loss=0.7300, Acc=0.7587, IoU=0.0961\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 40/50: 100%|██████████| 24/24 [03:11\u003c00:00,  7.98s/it, iou=0.14, loss=0.19]\n","Val Epoch 40/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.01s/it, iou=0.17, loss=0.72]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 40: Train Loss=0.5035, Acc=0.8075, IoU=0.1081 | Val Loss=0.7315, Acc=0.7589, IoU=0.0965\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 41/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.02s/it, iou=0.14, loss=0.20]\n","Val Epoch 41/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.05s/it, iou=0.16, loss=0.74]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 41: Train Loss=0.4973, Acc=0.8110, IoU=0.1088 | Val Loss=0.7475, Acc=0.7522, IoU=0.0955\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 42/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.02s/it, iou=0.14, loss=0.20]\n","Val Epoch 42/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.03s/it, iou=0.17, loss=0.74]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 42: Train Loss=0.4981, Acc=0.8100, IoU=0.1088 | Val Loss=0.7556, Acc=0.7486, IoU=0.0964\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 43/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.03s/it, iou=0.13, loss=0.22]\n","Val Epoch 43/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.01s/it, iou=0.16, loss=0.76]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 43: Train Loss=0.5036, Acc=0.8070, IoU=0.1089 | Val Loss=0.7565, Acc=0.7463, IoU=0.0971\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 44/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.01s/it, iou=0.14, loss=0.23]\n","Val Epoch 44/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.95s/it, iou=0.17, loss=0.71]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 44: Train Loss=0.5058, Acc=0.8058, IoU=0.1088 | Val Loss=0.7592, Acc=0.7467, IoU=0.0984\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 45/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.04s/it, iou=0.13, loss=0.25]\n","Val Epoch 45/50: 100%|██████████| 8/8 [01:04\u003c00:00,  8.04s/it, iou=0.16, loss=0.78]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 45: Train Loss=0.5139, Acc=0.8033, IoU=0.1084 | Val Loss=0.7563, Acc=0.7449, IoU=0.0975\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 46/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.03s/it, iou=0.14, loss=0.24]\n","Val Epoch 46/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.99s/it, iou=0.17, loss=0.74]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 46: Train Loss=0.5122, Acc=0.8033, IoU=0.1094 | Val Loss=0.7674, Acc=0.7445, IoU=0.0958\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 47/50: 100%|██████████| 24/24 [03:11\u003c00:00,  8.00s/it, iou=0.13, loss=0.23]\n","Val Epoch 47/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.98s/it, iou=0.16, loss=0.79]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 47: Train Loss=0.5077, Acc=0.8062, IoU=0.1093 | Val Loss=0.7686, Acc=0.7416, IoU=0.0944\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 48/50: 100%|██████████| 24/24 [03:12\u003c00:00,  8.01s/it, iou=0.14, loss=0.21]\n","Val Epoch 48/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.97s/it, iou=0.17, loss=0.74]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 48: Train Loss=0.5010, Acc=0.8089, IoU=0.1105 | Val Loss=0.7648, Acc=0.7494, IoU=0.0948\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 49/50: 100%|██████████| 24/24 [03:13\u003c00:00,  8.06s/it, iou=0.14, loss=0.19]\n","Val Epoch 49/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.95s/it, iou=0.16, loss=0.75]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 49: Train Loss=0.4823, Acc=0.8180, IoU=0.1112 | Val Loss=0.7410, Acc=0.7563, IoU=0.0967\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 50/50: 100%|██████████| 24/24 [03:13\u003c00:00,  8.05s/it, iou=0.14, loss=0.17]\n","Val Epoch 50/50: 100%|██████████| 8/8 [01:03\u003c00:00,  7.95s/it, iou=0.17, loss=0.73]"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 50: Train Loss=0.4669, Acc=0.8246, IoU=0.1131 | Val Loss=0.7365, Acc=0.7642, IoU=0.0971\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["wandb.init(\n","    project=\"dinov2-biotic-nb-08\",\n","    name=\"run-patchwise-mode\",  # Optionally change per experiment\n","    config={\n","        \"num_classes\": 18,\n","        \"batch_size\": 32,\n","        \"num_iters\": 50,\n","        \"hidden_dim\": 768,\n","        \"lr\": 1e-3\n","    }\n",")\n","\n","config = wandb.config\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size)\n","test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size)\n","\n","model = DINOPatchClassifier(num_classes=config.num_classes).to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","for iter in range(config.num_iters):\n","\n","    ### TRAINING ###\n","\n","    model.train()\n","    total_train_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    total_train_iou = 0.0\n","\n","    pbar = tqdm(train_dataloader, desc=f\"Train Epoch {iter+1}/{config.num_iters}\")\n","\n","    for batch in pbar:\n","        X_batch = batch[:, :-1]\n","        Y_batch = batch[:, -1]\n","\n","        Y = get_patchwise_mode(Y_batch)\n","        Y = rearrange(Y, 'n h w -\u003e (n h w)')\n","        Y = Y.to(device)\n","\n","        with torch.no_grad():\n","            X = get_dino_tokens_batch(X_batch)  # [N, 3601, D=384]\n","            X = X[:, 1:, :]  # drop CLS token\n","            X = rearrange(X, 'n p d -\u003e (n p) d')\n","            X = X.to(device)\n","\n","        optimizer.zero_grad()\n","        logits = model(X)\n","        loss = loss_fn(logits, Y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Stats\n","        batch_loss = loss.item()\n","        total_train_loss += batch_loss\n","\n","        preds = torch.argmax(logits, dim=1)\n","        correct_train += (preds == Y).sum().item()\n","        total_train += Y.size(0)\n","\n","        batch_iou = compute_iou(preds.cpu().numpy(), Y.cpu().numpy(), config.num_classes)\n","        total_train_iou += batch_iou\n","\n","        pbar.set_postfix(loss=f\"{batch_loss:.2f}\", iou=f\"{batch_iou:.2f}\")\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","    avg_train_accuracy = correct_train / total_train\n","    avg_train_iou = total_train_iou / len(train_dataloader)\n","\n","\n","\n","    # print(f\"Epoch {iter+1}: Train Loss={avg_train_loss:.4f}, Accuracy={avg_train_accuracy:.4f}, IoU={avg_train_iou:.4f}\")\n","\n","     ### VALIDATION ###\n","\n","    model.eval()\n","    total_val_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    total_val_iou = 0.0\n","\n","    with torch.no_grad():\n","        pbar = tqdm(test_dataloader, desc=f\"Val Epoch {iter+1}/{config.num_iters}\")\n","\n","        for batch in pbar:\n","            X_batch = batch[:, :-1]\n","            Y_batch = batch[:, -1]\n","\n","            Y = get_patchwise_mode(Y_batch)\n","            Y = rearrange(Y, 'n h w -\u003e (n h w)').to(device)\n","\n","            X = get_dino_tokens_batch(X_batch)\n","            X = X[:, 1:, :]\n","            X = rearrange(X, 'n p d -\u003e (n p) d').to(device)\n","\n","            logits = model(X)\n","            loss = loss_fn(logits, Y)\n","            batch_loss = loss.item()\n","            total_val_loss += batch_loss\n","\n","            preds = torch.argmax(logits, dim=1)\n","            correct_val += (preds == Y).sum().item()\n","            total_val += Y.size(0)\n","\n","            batch_iou = compute_iou(preds.cpu().numpy(), Y.cpu().numpy(), config.num_classes)\n","            total_val_iou += batch_iou\n","\n","            pbar.set_postfix(loss=f\"{batch_loss:.2f}\", iou=f\"{batch_iou:.2f}\")\n","\n","    avg_val_loss = total_val_loss / len(test_dataloader)\n","    avg_val_accuracy = correct_val / total_val\n","    avg_val_iou = total_val_iou / len(test_dataloader)\n","\n","    # ---------- LOGGING ----------\n","    wandb.log({\n","        \"epoch\": iter + 1,\n","        \"train/loss\": avg_train_loss,\n","        \"train/accuracy\": avg_train_accuracy,\n","        \"train/iou\": avg_train_iou,\n","        \"val/loss\": avg_val_loss,\n","        \"val/accuracy\": avg_val_accuracy,\n","        \"val/iou\": avg_val_iou\n","    })\n","    print()\n","\n","    print(f\"Epoch {iter+1}: \"\n","          f\"Train Loss={avg_train_loss:.4f}, Acc={avg_train_accuracy:.4f}, IoU={avg_train_iou:.4f} | \"\n","          f\"Val Loss={avg_val_loss:.4f}, Acc={avg_val_accuracy:.4f}, IoU={avg_val_iou:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvRR-p9itsxg"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMnmUgDfYyPKbxKXztZ8YwE","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}